{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "from itertools import permutations\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(file_name):\n",
    "\ttokens = \"\"\n",
    "\tnormalized = open(f\"{file_name.replace('train', 'normalized')}\", \"w+\")\n",
    "\twith open(file_name) as f:\n",
    "\t\t# asume that each line is a paragrap(block)\n",
    "\t\tfor text in f:\n",
    "\t\t\t# diacritics\n",
    "\t\t\ttext = text.strip()\n",
    "\t\t\ttext = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('ascii')\n",
    "\t\t\t# acronyms\n",
    "\t\t\tacronyms = re.findall(r\"\\b([A-Z]{2,}|[A-Z]+[0-9]+|[A-Z]+[a-z]+[A-Z])\", text)\n",
    "\t\t\tfor i, acronym in enumerate(acronyms):\n",
    "\t\t\t\tif any(char in string.punctuation for char in acronym) and len(acronym)>1:\n",
    "\t\t\t\t\tnormalized = \" \".join(acronym)\n",
    "\t\t\t\t\ttext = text.replace(acronym, normalized)\n",
    "\t\n",
    "\t\t\t# normalized.write('\\n')\n",
    "\t\t\t# Sentences split\n",
    "\t\t\ttext = re.sub(r\"([.!?])\\s\", \"\\n\", text)\n",
    "\t\t\t# Replace numbers with \"0\"\n",
    "\t\t\ttext = re.sub(r\"\\d\", \"0\", text)\n",
    "\t\t\t# Special characters\n",
    "\t\t\ttext = re.sub(r\"[^\\w\\s\\n]\", \"   \", text)\n",
    "\t\t\t# _ to space\n",
    "\t\t\ttext = re.sub(r\"_\", \" \", text)\n",
    "\t\t\t# Remove multiple space\n",
    "\t\t\ttext = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\t\t\t# Lowercase all letters\n",
    "\t\t\ttext = text.lower()\n",
    "\t\t\tnormalized.write(text)\n",
    "\t\t\tnormalized.write('\\n')\n",
    "\tnormalized.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_type(file_name: str) -> set:\n",
    "\tvocabs = set()\n",
    "\twith open(file_name) as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\ttmp = []\n",
    "\t\t\ttmp.extend(line)\n",
    "\t\t\tvocabs = vocabs.union(set(tmp))\n",
    "\treturn vocabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_gram(tokens, order=1):\n",
    "\tcounters = {}\n",
    "\tL = len(tokens) - order\n",
    "\tfor i in range(L):\n",
    "\t\tcurrent = \"\".join(tokens[i*order:(i+1)*order])\n",
    "\t\tif counters.get(current):\n",
    "\t\t\tcounters[current]+=1\n",
    "\t\telse:\n",
    "\t\t\tcounters[current] =1\n",
    "\treturn counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(files):\n",
    "\ttoken = []\n",
    "\twith open(files) as file:\n",
    "\t\tfor line in file:\n",
    "\t\t\ttoken.extend('\\\\'+line)\n",
    "\treturn token\n",
    "\n",
    "def sort_dict(dictionnary, key='val'):\n",
    "    if key=='key':\n",
    "    \treturn dict(sorted(dictionnary.items(), key=lambda items: items[0], reverse=True))        \n",
    "    else:\n",
    "    \treturn dict(sorted(dictionnary.items(), key=lambda items: items[1], reverse=True))        \n",
    "    \n",
    "def build_lm(ngram):\n",
    "    w = sum(ngram.values())\n",
    "    return {k:v/w for k, v in ngram.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "af_files = 'data/train.af.txt'\n",
    "en_files = 'data/train.en.txt'\n",
    "nl_files = 'data/train.nl.txt'\n",
    "xh_files = 'data/train.xh.txt'\n",
    "zu_files = 'data/train.zu.txt'\n",
    "normalize(af_files)\n",
    "normalize(en_files)\n",
    "normalize(nl_files)\n",
    "normalize(xh_files)\n",
    "normalize(zu_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_af_files = 'data/normalized.af.txt'\n",
    "norm_en_files = 'data/normalized.en.txt'\n",
    "norm_nl_files = 'data/normalized.nl.txt'\n",
    "norm_xh_files = 'data/normalized.xh.txt'\n",
    "norm_zu_files = 'data/normalized.zu.txt'\n",
    "\n",
    "af_token = tokenize(norm_af_files)\n",
    "en_token = tokenize(norm_en_files)\n",
    "nl_token = tokenize(norm_nl_files)\n",
    "xh_token = tokenize(norm_xh_files)\n",
    "zu_token = tokenize(norm_zu_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "af_trigram = n_gram(af_token, 3)\n",
    "en_trigram = n_gram(en_token, 3)\n",
    "nl_trigram = n_gram(nl_token, 3)\n",
    "xh_trigram = n_gram(xh_token, 3)\n",
    "zu_trigram = n_gram(zu_token, 3)\n",
    "\n",
    "af_trigram_model = build_lm(af_trigram)\n",
    "en_trigram_model = build_lm(en_trigram)\n",
    "nl_trigram_model = build_lm(nl_trigram)\n",
    "xh_trigram_model = build_lm(xh_trigram)\n",
    "zu_trigram_model = build_lm(zu_trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_af_files = 'data/val.af.txt'\n",
    "val_en_files = 'data/val.en.txt'\n",
    "val_nl_files = 'data/val.nl.txt'\n",
    "val_xh_files = 'data/val.xh.txt'\n",
    "val_zu_files = 'data/val.zu.txt'\n",
    "\n",
    "val_af_token = tokenize(val_af_files)\n",
    "val_en_token = tokenize(val_en_files)\n",
    "val_nl_token = tokenize(val_nl_files)\n",
    "val_xh_token = tokenize(val_xh_files)\n",
    "val_zu_token = tokenize(val_zu_files)\n",
    "\n",
    "val_af_trigram = n_gram(val_af_token, 3)\n",
    "val_en_trigram = n_gram(val_en_token, 3)\n",
    "val_nl_trigram = n_gram(val_nl_token, 3)\n",
    "val_xh_trigram = n_gram(val_xh_token, 3)\n",
    "val_zu_trigram = n_gram(val_zu_token, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(text):\n",
    "    score = {\n",
    "        'af': 0,\n",
    "        'en': 0,\n",
    "        'nl': 0,\n",
    "        'xh': 0,\n",
    "        'zu': 0\n",
    "    }\n",
    "    for trigram in text.keys():\n",
    "        score['af'] += af_trigram_model.get(trigram, 0)\n",
    "        score['en'] += en_trigram_model.get(trigram, 0)\n",
    "        score['nl'] += nl_trigram_model.get(trigram, 0)\n",
    "        score['xh'] += xh_trigram_model.get(trigram, 0)\n",
    "        score['zu'] += zu_trigram_model.get(trigram, 0)\n",
    "    # Softmax\n",
    "    score = {k:np.exp(v) for k,v in score.items()}\n",
    "    w = sum(x for x in score.values())\n",
    "    score = {k:np.round(v/w, 5) for k,v in score.items()}\n",
    "    return sort_dict(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'af': 0.20949, 'nl': 0.20555, 'en': 0.20246, 'zu': 0.1919, 'xh': 0.1906}\n",
      "{'en': 0.21346, 'nl': 0.20305, 'af': 0.20292, 'zu': 0.19085, 'xh': 0.18971}\n",
      "{'nl': 0.20937, 'af': 0.20717, 'en': 0.20356, 'zu': 0.19043, 'xh': 0.18946}\n",
      "{'xh': 0.20596, 'zu': 0.20478, 'en': 0.20045, 'nl': 0.19443, 'af': 0.19438}\n",
      "{'zu': 0.20459, 'xh': 0.2044, 'en': 0.20083, 'af': 0.19539, 'nl': 0.19479}\n"
     ]
    }
   ],
   "source": [
    "print(get_score(val_af_trigram))\n",
    "print(get_score(val_en_trigram))\n",
    "print(get_score(val_nl_trigram))\n",
    "print(get_score(val_xh_trigram))\n",
    "print(get_score(val_zu_trigram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 0.0046058,\n",
       " 'th ': 0.0006857,\n",
       " 'tha': 0.0005537,\n",
       " 'thi': 0.0003188,\n",
       " 'tho': 0.0002569,\n",
       " 'thr': 0.0002418,\n",
       " 'thn': 3.98e-05,\n",
       " 'ths': 2.47e-05,\n",
       " 'thu': 1.92e-05,\n",
       " 'thy': 9.6e-06,\n",
       " 'th\\n': 8.2e-06,\n",
       " 'thd': 4.1e-06,\n",
       " 'thl': 4.1e-06,\n",
       " 'thw': 4.1e-06,\n",
       " 'thp': 2.7e-06,\n",
       " 'thm': 2.7e-06,\n",
       " 'thc': 1.4e-06,\n",
       " 'tht': 1.4e-06}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th = {k:np.round(v,7) for k, v in en_trigram_model.items() if k.startswith('th')}\n",
    "sort_dict(th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
