{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from src.Normalizer import normalize_file\n",
    "from src.Tokenizer import Tokenizer, SentenceTokenizer\n",
    "from src.NgramModel import NGModel\n",
    "from src.LIdentify import LIdentify\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:44:49.937644Z",
     "start_time": "2024-06-27T10:44:49.752379Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Normalized Successfully!\n",
      "Document Normalized Successfully!\n",
      "Document Normalized Successfully!\n",
      "Document Normalized Successfully!\n",
      "Document Normalized Successfully!\n"
     ]
    }
   ],
   "source": [
    "af_file = 'data/train.af.txt'\n",
    "en_file = 'data/train.en.txt'\n",
    "nl_file = 'data/train.nl.txt'\n",
    "xh_file = 'data/train.xh.txt'\n",
    "zu_file = 'data/train.zu.txt'\n",
    "\n",
    "af_val_file = 'data/val.af.txt'\n",
    "en_val_file = 'data/val.en.txt'\n",
    "nl_val_file = 'data/val.nl.txt'\n",
    "xh_val_file = 'data/val.xh.txt'\n",
    "zu_val_file = 'data/val.zu.txt'\n",
    "\n",
    "norm_af_file = 'data/normalized.af.txt'\n",
    "norm_en_file = 'data/normalized.en.txt'\n",
    "norm_nl_file = 'data/normalized.nl.txt'\n",
    "norm_xh_file = 'data/normalized.xh.txt'\n",
    "norm_zu_file = 'data/normalized.zu.txt'\n",
    "\n",
    "normalize_file(af_file, norm_af_file)\n",
    "normalize_file(en_file, norm_en_file)\n",
    "normalize_file(nl_file, norm_nl_file)\n",
    "normalize_file(xh_file, norm_xh_file)\n",
    "normalize_file(zu_file, norm_zu_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = [' ','0','</s>','<s>','a','b','c',\n",
    "\t\t 'd','e','f','g','h','i','j','k',\n",
    "\t\t 'l','m','n','o','p','q','r','s',\n",
    "\t\t 't','u','v','w','x','y','z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:13:29.488522Z",
     "start_time": "2024-06-27T10:13:27.285791Z"
    }
   },
   "outputs": [],
   "source": [
    "af_model = NGModel(norm_af_file, CHARS, 'af', 3)\n",
    "en_model = NGModel(norm_en_file, CHARS, 'en', 3)\n",
    "nl_model = NGModel(norm_nl_file, CHARS, 'nl', 3)\n",
    "xh_model = NGModel(norm_xh_file, CHARS, 'xh', 3)\n",
    "zu_model = NGModel(norm_zu_file, CHARS, 'zu', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-482.0261844809487 -520.3255283503499 -495.1275058716431 -137.232557774365 -164.24989633845786\n"
     ]
    }
   ],
   "source": [
    "test = \"abantu basebenzisa olunye ulwimi lwokuthetha ebantwini kukho iilwimi ezininzi ezahlukileyo isingesi isixhosa isizulu isibhulu isisotho isipedi iinkonzo zeelwimi zesizwe\"\n",
    "a = SentenceTokenizer(test)\n",
    "af_lp, af_count = af_model.sent_logprob(a, 3)\n",
    "en_lp, en_count = en_model.sent_logprob(a, 3)\n",
    "nl_lp, nl_count = nl_model.sent_logprob(a, 3)\n",
    "xh_lp, xh_count = xh_model.sent_logprob(a, 3)\n",
    "zu_lp, zu_count = zu_model.sent_logprob(a, 3)\n",
    "print(af_lp, en_lp, nl_lp, xh_lp, zu_lp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k_list = np.linspace(1e-8,1, 400)\n",
    "# pp_list = []\n",
    "# for k in k_list:\n",
    "#     a, b = perplexity(en_val_file, en_model, 3, k)\n",
    "#     pp_list.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (af_model, en_model, nl_model, xh_model, zu_model)\n",
    "val_files = (af_val_file, en_val_file, nl_val_file, xh_val_file, zu_val_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model in models:\n",
    "#     for file in val_files:\n",
    "#         print(\"-\"*30)\n",
    "#         print(\"| model = \",model.name, \"|\",\n",
    "#               \"val file\",file.split('/')[-1].split('.')[1])\n",
    "#         hc, pp = perplexity(file, model, 3, 0.6)\n",
    "#         print(\"-\"*30)\n",
    "#         print(f\"|HC = {hc:.3f}, PP = {pp:.3f}\")\n",
    "#     print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>ther mand minen li x0 calgention thave expecal a posecuras thersishillect ed minamende logra itear ac'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.generate(start='t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:16:17.700906Z",
     "start_time": "2024-06-27T10:16:17.688863Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def perplexity(file_name, model, order, k=1e-8):\n",
    "    sum_prob = 0\n",
    "    sum_counter = 0\n",
    "    with open(file_name) as file:\n",
    "        for line in file:\n",
    "            token = SentenceTokenizer(line.strip())\n",
    "            a, b = model.sent_logprob(token, order, k)\n",
    "            sum_prob +=a \n",
    "            sum_counter +=b\n",
    "    hc = - sum_prob /sum_counter \n",
    "    pp = 2**hc \n",
    "    return hc, pp, np.exp(sum_prob)**(-1/sum_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "| model =  af | val file af\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_83247/4212415434.py:12: RuntimeWarning: divide by zero encountered in scalar power\n",
      "  return hc, pp, np.exp(sum_prob)**(-1/sum_counter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "|HC = 2.541, PP = 5.818, PP2 = inf\n",
      "------------------------------\n",
      "| model =  af | val file en\n",
      "------------------------------\n",
      "|HC = 3.285, PP = 9.748, PP2 = inf\n",
      "------------------------------\n",
      "| model =  af | val file nl\n",
      "------------------------------\n",
      "|HC = 2.791, PP = 6.923, PP2 = inf\n",
      "------------------------------\n",
      "| model =  af | val file xh\n",
      "------------------------------\n",
      "|HC = 3.856, PP = 14.479, PP2 = inf\n",
      "------------------------------\n",
      "| model =  af | val file zu\n",
      "------------------------------\n",
      "|HC = 3.900, PP = 14.930, PP2 = inf\n",
      "==============================\n",
      "------------------------------\n",
      "| model =  en | val file af\n",
      "------------------------------\n",
      "|HC = 3.314, PP = 9.943, PP2 = inf\n",
      "------------------------------\n",
      "| model =  en | val file en\n",
      "------------------------------\n",
      "|HC = 2.500, PP = 5.657, PP2 = inf\n",
      "------------------------------\n",
      "| model =  en | val file nl\n",
      "------------------------------\n",
      "|HC = 3.281, PP = 9.719, PP2 = inf\n",
      "------------------------------\n",
      "| model =  en | val file xh\n",
      "------------------------------\n",
      "|HC = 3.925, PP = 15.189, PP2 = inf\n",
      "------------------------------\n",
      "| model =  en | val file zu\n",
      "------------------------------\n",
      "|HC = 3.948, PP = 15.435, PP2 = inf\n",
      "==============================\n",
      "------------------------------\n",
      "| model =  nl | val file af\n",
      "------------------------------\n",
      "|HC = 2.773, PP = 6.835, PP2 = inf\n",
      "------------------------------\n",
      "| model =  nl | val file en\n",
      "------------------------------\n",
      "|HC = 3.140, PP = 8.815, PP2 = inf\n",
      "------------------------------\n",
      "| model =  nl | val file nl\n",
      "------------------------------\n",
      "|HC = 2.497, PP = 5.644, PP2 = inf\n",
      "------------------------------\n",
      "| model =  nl | val file xh\n",
      "------------------------------\n",
      "|HC = 3.944, PP = 15.392, PP2 = inf\n",
      "------------------------------\n",
      "| model =  nl | val file zu\n",
      "------------------------------\n",
      "|HC = 3.994, PP = 15.934, PP2 = inf\n",
      "==============================\n",
      "------------------------------\n",
      "| model =  xh | val file af\n",
      "------------------------------\n",
      "|HC = 3.581, PP = 11.968, PP2 = inf\n",
      "------------------------------\n",
      "| model =  xh | val file en\n",
      "------------------------------\n",
      "|HC = 3.223, PP = 9.339, PP2 = inf\n",
      "------------------------------\n",
      "| model =  xh | val file nl\n",
      "------------------------------\n",
      "|HC = 3.554, PP = 11.742, PP2 = inf\n",
      "------------------------------\n",
      "| model =  xh | val file xh\n",
      "------------------------------\n",
      "|HC = 2.579, PP = 5.975, PP2 = inf\n",
      "------------------------------\n",
      "| model =  xh | val file zu\n",
      "------------------------------\n",
      "|HC = 2.602, PP = 6.072, PP2 = inf\n",
      "==============================\n",
      "------------------------------\n",
      "| model =  zu | val file af\n",
      "------------------------------\n",
      "|HC = 3.601, PP = 12.137, PP2 = inf\n",
      "------------------------------\n",
      "| model =  zu | val file en\n",
      "------------------------------\n",
      "|HC = 3.311, PP = 9.928, PP2 = inf\n",
      "------------------------------\n",
      "| model =  zu | val file nl\n",
      "------------------------------\n",
      "|HC = 3.590, PP = 12.043, PP2 = inf\n",
      "------------------------------\n",
      "| model =  zu | val file xh\n",
      "------------------------------\n",
      "|HC = 2.711, PP = 6.546, PP2 = inf\n",
      "------------------------------\n",
      "| model =  zu | val file zu\n",
      "------------------------------\n",
      "|HC = 2.554, PP = 5.872, PP2 = inf\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    for file in val_files:\n",
    "        print(\"-\"*30)\n",
    "        print(\"| model = \",model.name, \"|\",\n",
    "              \"val file\",file.split('/')[-1].split('.')[1])\n",
    "        hc, pp, pp2 = perplexity(file, model, 3, 0.6)\n",
    "        print(\"-\"*30)\n",
    "        print(f\"|HC = {hc:.3f}, PP = {pp:.3f}, PP2 = {pp2:.3f}\")\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (af_model, en_model, nl_model, xh_model, zu_model)\n",
    "identifiers = LIdentify(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'val_af_grams' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(identifiers\u001b[38;5;241m.\u001b[39mscoring(\u001b[43mval_af_grams\u001b[49m[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(identifiers\u001b[38;5;241m.\u001b[39mscoring(val_en_grams[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(identifiers\u001b[38;5;241m.\u001b[39mscoring(val_nl_grams[\u001b[38;5;241m3\u001b[39m],\u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'val_af_grams' is not defined"
     ]
    }
   ],
   "source": [
    "print(identifiers.scoring(val_af_grams[3],3))\n",
    "print(identifiers.scoring(val_en_grams[3],3))\n",
    "print(identifiers.scoring(val_nl_grams[3],3))\n",
    "print(identifiers.scoring(val_xh_grams[3],3))\n",
    "print(identifiers.scoring(val_zu_grams[3],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
