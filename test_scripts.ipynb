{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from src.Normalizer import normalize_file\n",
    "from src.Tokenizer import Tokenizer\n",
    "from src.NgramModel import NGModel\n",
    "from src.LIdentify import LIdentify\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:44:49.937644Z",
     "start_time": "2024-06-27T10:44:49.752379Z"
    }
   },
   "outputs": [],
   "source": [
    "af_files = 'data/train.af.txt'\n",
    "en_files = 'data/train.en.txt'\n",
    "nl_files = 'data/train.nl.txt'\n",
    "xh_files = 'data/train.xh.txt'\n",
    "zu_files = 'data/train.zu.txt'\n",
    "\n",
    "norm_af_files = 'data/normalized.af.txt'\n",
    "norm_en_files = 'data/normalized.en.txt'\n",
    "norm_nl_files = 'data/normalized.nl.txt'\n",
    "norm_xh_files = 'data/normalized.xh.txt'\n",
    "norm_zu_files = 'data/normalized.zu.txt'\n",
    "\n",
    "# normalize_file(af_files, norm_af_files)\n",
    "# normalize_file(en_files, norm_en_files)\n",
    "# normalize_file(nl_files, norm_nl_files)\n",
    "# normalize_file(xh_files, norm_xh_files)\n",
    "# normalize_file(zu_files, norm_zu_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHARS = [' ','0','</s>','<s>','a','b','c',\n",
    "         'd','e','f','g','h','i','j','k',\n",
    "         'l','m','n','o','p','q','r','s',\n",
    "         't','u','v','w','x','y','z']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.Tokenizer import Tokenizer\n",
    "import numpy as np\n",
    "from src.utils import sort_dict\n",
    "\n",
    "\n",
    "class NGModel:\n",
    "    def __init__(self, file_name: str, vocab:list, name: str, orders: int = 1):\n",
    "        self.vocab = vocab\n",
    "        self.token = Tokenizer(file_name)\n",
    "        self.orders = orders\n",
    "        self.name = name\n",
    "        self.log_joints = self.__get_probs()\n",
    "\n",
    "    def __ngram(self, tokens, order):\n",
    "        counters = {}\n",
    "        L = len(tokens) - order\n",
    "        for i in range(L):\n",
    "            current = tuple(tokens[i * order:(i + 1) * order])\n",
    "            if counters.get(current):\n",
    "                counters[current] += 1\n",
    "            else:\n",
    "                counters[current] = 1\n",
    "        return counters\n",
    "\n",
    "    def __get_probs(self):\n",
    "        ngrams = {}\n",
    "        token_list = list(self.token)\n",
    "        for order in range(1, self.orders + 1):\n",
    "            _tmp = self.__ngram(token_list, order)\n",
    "            w = sum(_tmp.values())\n",
    "            ngrams[order] = sort_dict({k: v/w\n",
    "                                      for k, v in _tmp.items()})\n",
    "        return ngrams\n",
    "    \n",
    "    def generate(self, start, max_len=100, smoothing=0):\n",
    "        text = '<s>'+start\n",
    "        tokens = [\"<s>\", start]\n",
    "        for _ in range(max_len):\n",
    "            tokens = tokens[-(self.orders -2):]\n",
    "            probs = self.__get_next_probs(tokens, smoothing)\n",
    "            next_word = self.__sample_word(probs)\n",
    "            tokens.append(next_word)\n",
    "            text += ''.join(next_word)\n",
    "        return text\n",
    "    \n",
    "    def __addk(self, numer, denom, smoothing):\n",
    "        b = \n",
    "        return a/b\n",
    "    \n",
    "    def __get_next_probs(self, tokens, smoothing):\n",
    "        order = self.orders\n",
    "        context= tuple(tokens[-(self.orders -2):])\n",
    "        pcontext = self.log_joints[self.orders -1].get(context, 0) + smoothing * len(self.vocab) \n",
    "        probs = np.zeros((len(self.vocab),))\n",
    "        for i in range(len(self.vocab)):\n",
    "            joint = tuple(tokens[-(self.orders -2):] + [self.vocab[i]])\n",
    "        \tpjoint= self.log_joints[self.orders].get(joint, 0) + smoothing\n",
    "            probs[i] = pjoint/pcontext\n",
    "        print(sum(probs))\n",
    "        return probs/sum(probs)\n",
    "    \n",
    "    def __sample_word(self, probs):\n",
    "        idx = np.random.multinomial(1, probs).argmax() \n",
    "        return self.vocab[idx]\n",
    "    \n",
    "    def perplexity(self, text, order):\n",
    "        token = ['<s>']\n",
    "        token.extend(text)\n",
    "        token +=['</s>']\n",
    "        N = len(token)\n",
    "        P = 1\n",
    "        for i in range(N-1):\n",
    "            joint = token[i*(order):(i+1)*order]\n",
    "            den = joint[:-1]\n",
    "            p = self.log_joints[order].get(tuple(joint), 0)/self.log_joints[order -1].get(tuple(den), 0)\n",
    "            P *=(1/p)\n",
    "        return P**(1/N)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:13:29.488522Z",
     "start_time": "2024-06-27T10:13:27.285791Z"
    }
   },
   "outputs": [],
   "source": [
    "# af_model = NGModel(norm_af_files, CHARS, 'af', 3)\n",
    "en_model = NGModel(norm_en_files, CHARS, 'en', 3)\n",
    "# nl_model = NGModel(norm_nl_files, CHARS, 'nl', 3)\n",
    "# xh_model = NGModel(norm_xh_files, CHARS, 'xh', 3)\n",
    "# zu_model = NGModel(norm_zu_files, CHARS, 'zu', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>t</s>atmftxryqjme<s>lldckcrptjowk0gsi0mkwkqvyjgkmwxnmublkxv lqa<s>rbbcvuaml</s>ukmptz<s>eitwhl xk0xoyqpdsb0pmouku'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.generate(start='t', smoothing=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m en_model\u001b[39m.\u001b[39;49mperplexity(\u001b[39m\"\u001b[39;49m\u001b[39mbonjour mon coeur\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m3\u001b[39;49m)\n",
      "\u001b[1;32m/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb Cell 9\u001b[0m line \u001b[0;36m7\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=68'>69</a>\u001b[0m     joint \u001b[39m=\u001b[39m token[i\u001b[39m*\u001b[39m(order):(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39morder]\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=69'>70</a>\u001b[0m     den \u001b[39m=\u001b[39m joint[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=70'>71</a>\u001b[0m     p \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_joints[order]\u001b[39m.\u001b[39;49mget(\u001b[39mtuple\u001b[39;49m(joint), \u001b[39m0\u001b[39;49m)\u001b[39m/\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_joints[order \u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49mget(\u001b[39mtuple\u001b[39;49m(den), \u001b[39m0\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=71'>72</a>\u001b[0m     P \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mp)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X30sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m \u001b[39mreturn\u001b[39;00m P\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m(\u001b[39m1\u001b[39m\u001b[39m/\u001b[39mN)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "en_model.perplexity(\"bonjour mon coeur\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:16:17.685212Z",
     "start_time": "2024-06-27T10:16:16.298485Z"
    }
   },
   "outputs": [],
   "source": [
    "val_af_files = 'data/val.af.txt'\n",
    "val_en_files = 'data/val.en.txt'\n",
    "val_nl_files = 'data/val.nl.txt'\n",
    "val_xh_files = 'data/val.xh.txt'\n",
    "val_zu_files = 'data/val.zu.txt'\n",
    "\n",
    "val_af_token = Tokenizer(val_af_files)\n",
    "val_en_token = Tokenizer(val_en_files)\n",
    "val_nl_token = Tokenizer(val_nl_files)\n",
    "val_xh_token = Tokenizer(val_xh_files)\n",
    "val_zu_token = Tokenizer(val_zu_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>w0<s>limobagkceoem0brv</s>d</s>kvge</s>qmn0h</s>zubmfgo ilyv <s>apatfropgtsb</s>so sxlhv<s>ysxhedrj0xrc ojvyrncasmuvijbjkx'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_model.generate(start='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-27T10:16:17.700906Z",
     "start_time": "2024-06-27T10:16:17.688863Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "val_af_grams = val_af_token.build_ngram(3)\n",
    "val_en_grams = val_en_token.build_ngram(3)\n",
    "val_nl_grams = val_nl_token.build_ngram(3)\n",
    "val_xh_grams = val_xh_token.build_ngram(3)\n",
    "val_zu_grams = val_zu_token.build_ngram(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(' ',),\n",
       " ('0',),\n",
       " ('</s>',),\n",
       " ('<s>',),\n",
       " ('a',),\n",
       " ('b',),\n",
       " ('c',),\n",
       " ('d',),\n",
       " ('e',),\n",
       " ('f',),\n",
       " ('g',),\n",
       " ('h',),\n",
       " ('i',),\n",
       " ('j',),\n",
       " ('k',),\n",
       " ('l',),\n",
       " ('m',),\n",
       " ('n',),\n",
       " ('o',),\n",
       " ('p',),\n",
       " ('q',),\n",
       " ('r',),\n",
       " ('s',),\n",
       " ('t',),\n",
       " ('u',),\n",
       " ('v',),\n",
       " ('w',),\n",
       " ('x',),\n",
       " ('y',),\n",
       " ('z',)}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(val_en_grams[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = (af_model, en_model, nl_model, xh_model, zu_model)\n",
    "identifiers = LIdentify(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NGModel' object has no attribute 'ngrams'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb Cell 12\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(identifiers\u001b[39m.\u001b[39;49mscoring(val_af_grams[\u001b[39m3\u001b[39;49m],\u001b[39m3\u001b[39;49m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mprint\u001b[39m(identifiers\u001b[39m.\u001b[39mscoring(val_en_grams[\u001b[39m3\u001b[39m],\u001b[39m3\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/jlr/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/test_scripts.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(identifiers\u001b[39m.\u001b[39mscoring(val_nl_grams[\u001b[39m3\u001b[39m],\u001b[39m3\u001b[39m))\n",
      "File \u001b[0;32m~/Workspaces/SU/09-NLP/NLP_LANG_IDsCOMP/src/LIdentify.py:14\u001b[0m, in \u001b[0;36mLIdentify.scoring\u001b[0;34m(self, unknown, order)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39mfor\u001b[39;00m gram \u001b[39min\u001b[39;00m unknown:\n\u001b[1;32m     13\u001b[0m     \u001b[39mfor\u001b[39;00m model \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodels:\n\u001b[0;32m---> 14\u001b[0m         score[model\u001b[39m.\u001b[39mname] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mngrams[order]\u001b[39m.\u001b[39mget(gram, \u001b[39m0\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mreturn\u001b[39;00m sort_dict(score)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NGModel' object has no attribute 'ngrams'"
     ]
    }
   ],
   "source": [
    "print(identifiers.scoring(val_af_grams[3],3))\n",
    "print(identifiers.scoring(val_en_grams[3],3))\n",
    "print(identifiers.scoring(val_nl_grams[3],3))\n",
    "print(identifiers.scoring(val_xh_grams[3],3))\n",
    "print(identifiers.scoring(val_zu_grams[3],3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
